{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bd3fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Textprocessor import TextProcessor\n",
    "from createModel import CreateModel\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import re \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43893d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5007, 5006, 18, 16, 19, 20, 21, 22, 23, 24, 16, 25, 26, 27, 28, 29, 30, 31, 32, 16, 33, 34, 6, 29, 35, 36, 5005]\n",
      "[5007 5006   18   16   19   20   21   22   23   24   16   25   26]\n",
      "[5007   37 5005    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.62 GiB for an array with shape (408408, 5008) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-79a8fad8451b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m \u001b[0mchatbot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mChatbot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[0mprepro1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mprepro1\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'q'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-79a8fad8451b>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetVocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_to_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv_vocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_inp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder_inp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder_final_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEncodeQuestionAndResponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m#declarations des inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc_inp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Master_UVS\\projet_chatbot\\Textprocessor.py\u001b[0m in \u001b[0;36mEncodeQuestionAndResponse\u001b[1;34m(self, vocab, questions, responses)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mdecoder_final_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_final_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mdecoder_final_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_final_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m   \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m   \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m   \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.62 GiB for an array with shape (408408, 5008) and data type float32"
     ]
    }
   ],
   "source": [
    "class Chatbot:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.corpus=TextProcessor()\n",
    "        self.createmodel=CreateModel()\n",
    "        self.questions,self.responses=self.corpus.load_corpus('movie_lines.txt','movie_conversations.txt')\n",
    "        self.questions,self.responses=self.corpus.CleanQuestionAndAnswer(self.questions,self.responses)\n",
    "        self.word_to_count=self.corpus.wordToCount(self.questions,self.responses)\n",
    "        self.vocab=self.corpus.getVocab(self.word_to_count,self.responses)\n",
    "        self.inv_vocab = {w:v for v, w in self.vocab.items()}\n",
    "        self.encoder_inp,self.decoder_inp,self.decoder_final_output=self.corpus.EncodeQuestionAndResponse(self.vocab,self.questions,self.responses)\n",
    "        #declarations des inputs \n",
    "        self.enc_inp = Input(shape=(13, ))\n",
    "        self.dec_inp = Input(shape=(13, ))\n",
    "        self.model,self.enc_model,self.dec_model,self.dense=self.createmodel\n",
    "        .create_model(self.vocab,self.enc_inp,self.dec_inp )\n",
    "        \n",
    "        #self.model.load_weights(\"chatbot-model.hdf5\")\n",
    "        model_file=\"chatbot-model_test.hdf5\"\n",
    "\n",
    "        checkpoint = ModelCheckpoint(model_file, \n",
    "                                    monitor='val_loss', \n",
    "                                    verbose=1, \n",
    "                                    save_best_only=True, \n",
    "                                    save_weights_only=False\n",
    "                                    )\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', \n",
    "                        mode='min',\n",
    "                        patience=10)\n",
    "\n",
    "        callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "        self.model.fit([self.encoder_inp, self.decoder_inp],self.decoder_final_output, \n",
    "                            epochs=10,\n",
    "                            verbose=1,\n",
    "                            shuffle=True,\n",
    "                            callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n",
    "    # prepo1 is the question of the user \n",
    "    def getQuestionGiveAnswer(self ,prepro1,vocab,enc_model,dec_model,dense,inv_vocab):\n",
    "\n",
    "        prepro1 = self.CleanText(prepro1)\n",
    "        ## prepro1 = \"hello\"\n",
    "\n",
    "        prepro = [prepro1]\n",
    "        ## prepro1 = [\"hello\"]\n",
    "\n",
    "        txt = []\n",
    "        for x in prepro:\n",
    "            # x = \"hello\"\n",
    "            lst = []\n",
    "            for y in x.split():\n",
    "\n",
    "                ## y = \"hello\"\n",
    "                try:\n",
    "                    lst.append(vocab[y])\n",
    "                    ## vocab['hello'] = 454\n",
    "                except:\n",
    "                    lst.append(vocab['<OUT>'])\n",
    "            txt.append(lst)\n",
    "\n",
    "        ## txt = [[454]]\n",
    "        txt = pad_sequences(txt, 13, padding='post')\n",
    "\n",
    "        ## txt = [[454,0,0,0,.........13]]\n",
    "\n",
    "        stat = enc_model.predict( txt )\n",
    "\n",
    "        empty_target_seq = np.zeros( ( 1 , 1) )\n",
    "        ##   empty_target_seq = [0]\n",
    "\n",
    "\n",
    "        empty_target_seq[0, 0] = vocab['<SOS>']\n",
    "        ##    empty_target_seq = [255]\n",
    "\n",
    "        stop_condition = False\n",
    "        decoded_translation = ''\n",
    "\n",
    "        while not stop_condition :\n",
    "\n",
    "            dec_outputs , h, c= dec_model.predict([ empty_target_seq] + stat )\n",
    "            decoder_concat_input = dense(dec_outputs)\n",
    "            ## decoder_concat_input = [0.1, 0.2, .4, .0, ...............]\n",
    "\n",
    "            sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n",
    "            ## sampled_word_index = [2]\n",
    "\n",
    "            sampled_word = inv_vocab[sampled_word_index] + ' '\n",
    "\n",
    "            ## inv_vocab[2] = 'hi'\n",
    "            ## sampled_word = 'hi '\n",
    "\n",
    "            if sampled_word != '<EOS> ':\n",
    "                decoded_translation += sampled_word  \n",
    "\n",
    "            if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
    "                stop_condition = True \n",
    "\n",
    "            empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "            empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "            ## <SOS> - > hi\n",
    "            ## hi --> <EOS>\n",
    "            stat = [h, c]  \n",
    "\n",
    "        print(\"chatbot attention : \", decoded_translation )\n",
    "\n",
    "        return decoded_translation\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "chatbot=Chatbot()\n",
    "prepro1 = \"\"\n",
    "while prepro1 != 'q':\n",
    "    prepro1  = input(\"you : \")\n",
    "    chatbot.getQuestionGiveAnswer(prepro1,chatbot.vocab,chatbot.enc_model,chatbot.dec_model,chatbot.dense,chatbot.inv_vocab)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525515cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8e1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
